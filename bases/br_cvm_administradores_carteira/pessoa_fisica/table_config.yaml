
dataset_id: br_cvm_administradores_carteira

table_id: pessoa_fisica

# Descreva a tabela. Essas são as primeiras frases que um usuário vai ver.
# Você não precisa ser muito conciso. Sinta-se a vontade para dar exemplos de
# como usar os dados.
# Se souber, liste também aplicações: pesquisa, apps, etc. que usem os dados.,
description: Administradores de pessoa física.

# A máxima unidade espacial que a tabela cobre.
spatial_coverage:
    continent:
        - south_america
    country:
        - bra

# Anos cobertos pela tabela.
# Preencher como lista de intervalos.
# Exemplo: 1995(1)2019.
temporal_coverage:
    - 1988
    - 1989
    - 1990
    - 1991
    - 1992
    - 1993
    - 1994
    - 1995
    - 1996
    - 1997
    - 1998
    - 1999
    - 2000
    - 2001
    - 2002
    - 2003
    - 2004
    - 2005
    - 2006
    - 2007
    - 2008
    - 2009
    - 2010
    - 2011
    - 2012
    - 2013
    - 2014
    - 2015
    - 2016
    - 2017
    - 2018
    - 2019
    - 2020
    - 2021
    - 2022

# A unidade temporal com qual a tabela é atualizada.
# Opções em 'https://basedosdados.org/api/3/action/bd_available_options'
update_frequency: day

# Entidade representada por cada linha.
# Opções em 'https://basedosdados.org/api/3/action/bd_available_options'
entity: person

# A unidade temporal representada por cada linha.
# Opções em 'https://basedosdados.org/api/3/action/bd_available_options'
time_unit:

# O conjunto mínimo de colunas identificando cada linha unicamente.
# Preencha com os nomes de colunas.
# Exemplos: id_municipio, ano.
# Pode ser vazio pois certas tabelas não possuem identificadores.
identifying_columns:
    - nome
    - data_registro

last_updated:
    metadata:
    data:
    release:

# Versão da tabela. Seguindo o padrão de semantic versioning.
# Exemplo: v1.1.3
version: v0.1

# Quem está preenchendo esses metadados?
published_by:
    name: Ricardo Dahis
    email: rdahis@basedosdados.org
    github_user: rdahis
    ckan_user: rdahis
    website: www.ricardodahis.com

# Qual organização/departamento/pessoa tratou os dados?
# As vezes há um ponto intermediário entre os dados originais e subir na Base dos Dados.
# Se essa pessoa é você, preencha abaixo com suas informações.
data_cleaned_by:
    name: Ricardo Dahis
    email: rdahis@basedosdados.org
    github_user: rdahis
    ckan_user: rdahis
    website: www.ricardodahis.com
    code_url:

# Se houve passos de tratamento, limpeza e manipulação de dados, descreva-os aqui.
data_cleaning_description:

# Url dos dados originais no GCP Storage.
raw_files_url:

# Url dos arquivos auxiliares no GCP Storage.
auxiliary_files_url:

# Url da tabela de arquitetura no GCP Storage.
architecture_url:

# A tabela tem colunas que precisam de dicionário?
# Opções: yes, no.
covered_by_dictionary:

source_bucket_name: basedosdados-dev

project_id_prod: basedosdados-dev

project_id_staging: basedosdados-dev

# Liste as colunas da tabela que representam partições.
# Não esqueça de deletar essas colunas nas tabelas .csv na hora de subir para o BigQuery.
# Isso poupará muito tempo e dinheiro às pessoas utilizando essa tabela.
# Se não houver partições, não modifique abaixo.
partitions:

bdm_file_size:

# Quais são as colunas? Certifique-se de escrever uma boa descrição, as pessoas vão gostar
# para saber sobre o que é a coluna.
# Adicionar todas as colunas manualmente pode ser bastante cansativo, por isso, quando
# inicializando este arquivo de configuração, você pode apontar a função para uma amostra de dados que
# preencherá automaticamente as colunas.
# Algumas colunas existirão apenas na tabela final, você as construirá em `publish.sql`.
# Para esses, defina is_in_staging como False.
# Além disso, você deve adicionar as colunas de partição aqui e definir is_partition como True.
columns:
    - name: nome
      bigquery_type: string
      description: Nome
      temporal_coverage:
      covered_by_dictionary: no
      directory_column:
          dataset_id:
          table_id:
          column_name:
      measurement_unit:
      has_sensitive_data: yes
      is_in_staging: true
      is_partition: false
    - name: data_registro
      bigquery_type: date
      description: Data de registro
      temporal_coverage:
      covered_by_dictionary: no
      directory_column:
          dataset_id: br_bd_diretorios_data_tempo
          table_id: data
          column_name: data
      measurement_unit:
      has_sensitive_data: no
      is_in_staging: true
      is_partition: false
    - name: data_cancelamento
      bigquery_type: date
      description: Data de cancelamento
      temporal_coverage:
      covered_by_dictionary: no
      directory_column:
          dataset_id: br_bd_diretorios_data_tempo
          table_id: data
          column_name: data
      measurement_unit:
      has_sensitive_data: no
      is_in_staging: true
      is_partition: false
    - name: motivo_cancelamento
      bigquery_type: string
      description: Motivo de cancelamento
      temporal_coverage:
      covered_by_dictionary: no
      directory_column:
          dataset_id:
          table_id:
          column_name:
      measurement_unit:
      has_sensitive_data: no
      is_in_staging: true
      is_partition: false
    - name: situacao
      bigquery_type: string
      description: Situação
      temporal_coverage:
      covered_by_dictionary: no
      directory_column:
          dataset_id:
          table_id:
          column_name:
      measurement_unit:
      has_sensitive_data: no
      is_in_staging: true
      is_partition: false
    - name: data_inicio_situacao
      bigquery_type: date
      description: Data de início da situação
      temporal_coverage:
      covered_by_dictionary: no
      directory_column:
          dataset_id: br_bd_diretorios_data_tempo
          table_id: data
          column_name: data
      measurement_unit:
      has_sensitive_data: no
      is_in_staging: true
      is_partition: false
    - name: categoria_registro
      bigquery_type: string
      description: Categoria de registro
      temporal_coverage:
      covered_by_dictionary: no
      directory_column:
          dataset_id:
          table_id:
          column_name:
      measurement_unit:
      has_sensitive_data: no
      is_in_staging: true
      is_partition: false

metadata_modified: '2022-01-26T20:13:19.454811'
